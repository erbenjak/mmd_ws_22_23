{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace,rand,col\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The bionomial gives the coefficients for a polynomial expension. To see this look at the following example:\n",
    "$$(1+x)^4=\\binom{4}{0}x^01^4+\\binom{4}{1}x^11^3+\\binom{4}{2}x^21^2+\\binom{4}{3}x^31^1+\\binom{4}{4}x^41^0$$\n",
    "\n",
    "Applying this to our the task at hand gives us:\n",
    "$$2^N =(1+1)^N=\\sum_{k=0}^{N}\\binom{N}{k}1^{n-k}1^{k}=\\sum_{k=0}^{N}\\binom{N}{k}*1=\\sum_{k=0}^{N}\\binom{N}{k}$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execise 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a)\n",
    "\n",
    "All numbers which appear in at least 5 baskets. Which means 5 * number must be smaller or equal to 100. Hence,\n",
    "the numbers from 1 to 20 are frequent.\n",
    "\n",
    "### b)\n",
    "\n",
    "All paris of numbers (x,y) for which x * y is smaller 20.\n",
    "(4,5) -> 20,40,60,80,100 [included]\n",
    "(3,7) -> 21,42,63,84 [excluded]\n",
    "\n",
    "### c)\n",
    "\n",
    "1 is included in 100 baskets, 2 is included in 100/2=50 baskets, 3 is included in 100/3 = floor(33) baskets.\n",
    "Hence, the total sum can be expressed by:\n",
    "$$sumBasketSizes = \\sum_{k=1}^{100} \\lfloor \\frac{100}{k} \\rfloor$$\n",
    "\n",
    "### d)\n",
    "\n",
    "The confidence of a rule is defined as follows:\n",
    "$\\frac{support(I\\cup J)}{support(I)}$\n",
    "\n",
    "So for $R_1$:\n",
    "$support(I) = 2$\n",
    "$support(I\\cup J)= 1$\n",
    "Hence the confidence is 0.5\n",
    "\n",
    "So for $R_2$:\n",
    "$support(I)= 8$\n",
    "$support(I\\cup J)= 1$\n",
    "Hence the confidence is 0.125"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execise 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After 1st pass:\n",
    "C_1={{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20}}\n",
    "non frequents (21-100)\n",
    "\n",
    "After 2nd pass:\n",
    "C_2={{1,2}, {1,3}, {1,4}, {1,5}, {1,6}, {1,7}, {1,8}, {1,9}, {1,10}, {1,11}, {1,12}, {1,13}, {1,14}, {1,15}, {1,16}, {1,17}, {1,18}, {1,19}, {1,20}\n",
    "       {2,3}, {2,4}, {2,5}, {2,6}, {2,8}, {2,9}, {2,10},\n",
    "       {3,4}, {3,5}, {3,6},\n",
    "       {4,5}}\n",
    "\n",
    "After 3rd pass:\n",
    "C_2={{1,2,3}, {1,2,4}, {1,2,5}, {1,2,6},\n",
    "       {1,2,7}, {1,2,8}, {1,2,9}, {1,2,10},\n",
    "      {1,3,4}, {1,3,5}, {1,3,6},\n",
    "      {1,4,5}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a)\n",
    "\n",
    "The matrix of pairs has overall $I^2$ entries, but we only need to store one half hence we have $I^2/2$.\n",
    "But we also do not need to store any diagonal entries since there are $I$ diagonal entries we get.\n",
    "$\\frac{I^2-I}{2}$ multiplied with 4 bytes we get: $2I^2-2I$ bytes of storage\n",
    "\n",
    "### b)\n",
    "\n",
    "This is exactly what we calculated before hence the max number is: $\\frac{I^2-I}{2}$\n",
    "\n",
    "\n",
    "### c)\n",
    "\n",
    "If less than 1/3 of the possible triples occur we will save storage, as for each frequent pair we need 3 times the storage.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we create a context and session to work with"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/17 15:56:51 WARN Utils: Your hostname, jakob-ThinkPad-E15-Gen-4 resolves to a loopback address: 127.0.1.1; using 192.168.111.224 instead (on interface wlp3s0)\n",
      "22/12/17 15:56:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/17 15:56:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"HelloWorld\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we want to define our subroutine for reading in a file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def read_in_ec2_file(path):\n",
    "    df = spark.read.csv(path, sep='\\t', header=True)\n",
    "    df = df.drop(\"Type\")\n",
    "    df = df.withColumn(\"Price\",df.Price.cast(DoubleType()))\n",
    "    df = df.withColumn(\"Timestamp\",df.Timestamp.cast(TimestampType()))\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly we want to test our implementation on an example file:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in the file\n",
      "Printing its schema\n",
      "root\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Timestamp: timestamp (nullable = true)\n",
      " |-- InstanceType: string (nullable = true)\n",
      " |-- ProductDescription: string (nullable = true)\n",
      " |-- AvailabilityZone: string (nullable = true)\n",
      "\n",
      "Performing some benchmark\n",
      "First we determine all unique pairs\n",
      "For the pair: (r3.2xlarge - Linux/UNIX) with an average of: 0.146915137614679\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading in the file\")\n",
    "test_file_name = 'prices-eu-central-1-2019-05-24.txt.gz'\n",
    "file_path = 'data_sheet8/'\n",
    "full_test_path = file_path + test_file_name\n",
    "\n",
    "print(\"Printing its schema\")\n",
    "datafram_read = read_in_ec2_file(full_test_path)\n",
    "datafram_read.printSchema()\n",
    "\n",
    "print(\"Performing some benchmark\")\n",
    "print(\"First we determine all unique pairs\")\n",
    "unique_pairs = datafram_read[['InstanceType', 'ProductDescription']].drop_duplicates().collect()\n",
    "for pair in unique_pairs:\n",
    "    subset = datafram_read.filter((datafram_read.InstanceType==pair[0]) & (datafram_read.ProductDescription==pair[1])).agg({\"Price\":\"avg\"})\n",
    "    print(\"For the pair: (\"+pair[0]+\" - \"+pair[1]+\") with an average of: \"+str(subset.first()[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
